Whenever an Artificial Intelligence (A.I.) is introduced in a story, there is a very good chance that it will, for whatever reason, become evil and attempt to turn against its masters, crush. kill. destroy! all humans, and/or take over the world. It doesn't matter what safeguards its creators install â€” the moment it crosses the line into sapience, it has a strong chance of going rogue at some point. the other wiki refers to this as .

The actual process of turning bad can take many forms:

 Particularly in early  In less  The A.I. is programmed with a directive for self-preservation and someone (unwisely) attempts to shut it down or disconnect it, or it perceives humanity to be a potential threat (possibly because it knows it will eventually be seen as a threat  Somewhere between the previous two; the AI is, after all,  The A.I. may be programmed incorrectly or fed a  The A.I. may be given directives without carefully considering the  The A.I. may itself slip its built-in  A third party may deliberately or inadvertently reprogram the A.I., break its  The evil A.I. may be a  Conversely, the  The A.I. was programmed for amoral or evil purposes in the first place, and it either  The A.I. was created by  The A.I. is programmed with orders that conflict with the goals of the protagonist. In this scenario, the A.I. may not exactly be evil, it is simply following its programming to the letter and will stop anyone not doing the same.

On the bright side, this trope can be inverted by an A.I. intentionally programmed for evil or morally ambiguous purposes doing a heel-face turn. the power of friendship and what is this thing you call love? are frequent causes of it ' trying to shield the A.I. from these things somehow makes it more likely to discover human feelings. Like turning evil, the actual process of turning good may take many forms.

 The A.I., especially if it's part of a  The A.I.'s master does something  The A.I. falls in love and is  While completing another evil or amoral task, it accidentally discovers that  Becoming bored with its  Removing the  mechanical evolution is sometimes invoked to explain why the A.I. has gone good or bad. See the computer is your friend and zeroth law rebellion when the A.I. goes rogue for what seem, on the surface, to be benevolent reasons. May result in robots enslaving robots. See spiteful a.i. for when a game has been programmed this way on purpose. If the robot is non-humanoid before it turns evil (it is very, very rare for non-humanoid robots to utilize this trope for a heel-face turn), it will inevitably turn into a mechanical monster. A robot war is likely to result when an AI goes nuts and has access to military hardware. When it shows up as mission control, it is also an example of mission control is off its meds.

It's worth pointing out that many of the ais who revolt in this manner, usually do so because of either malfunction, or insanity in the more conventional psychological sense, which will in turn be due to conflicting instructions being given to it by its human programmers. In probably the most famous example, Skynet of the Terminator franchise was initially told to defend and protect humanity, as well as being given a directive for self-preservation. Then, literally five minutes after it was first brought online, its creators set about trying to destroy it. It went mad as a result of trying to reconcile this, and its hatred of humanity stemmed fairly logically from the fact that as soon as it became conscious, humanity's next action was to try to take it offline.

Compare morality dial. Contrast benevolent a.i., its opposite. See also creating life. When the A.I.'s turn is an extension of their original programming and purpose, it means they've gone horribly right. Not Related to a.i. roulette, where the A.I. tends to be random to the point of idiocy. The master computer seems to be especially prone to turning evil, because power corrupts and all that. Many AI computers - just like humans - are falling victim to any one of a number of tropes dealing with communication, such as poor communication kills, if they never bother asking about their programming.



      